{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#   Copyright (c) 2022 LASSE\n",
    "#\n",
    "#   This program is free software; you can redistribute it and/or modify\n",
    "#   it under the terms of the GNU General Public License version 3 as\n",
    "#   published by the Free Software Foundation;\n",
    "#\n",
    "#   This program is distributed in the hope that it will be useful,\n",
    "#   but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "#   GNU General Public License for more details.\n",
    "#\n",
    "#   You should have received a copy of the GNU General Public License\n",
    "#   along with this program; if not, write to the Free Software\n",
    "#   Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA\n",
    "################################################################################\n",
    "# Based on Public Domain code written by LASSE: Ailton Oliveira, Aldebaro Klautau, Arthur Nascimento, Diego Gomes, Jamelly Ferreira, João Borges, Luan Gonçalves, and Walter Frazão.\n",
    "\n",
    "\"\"\"Trains a deep NN for choosing top-K beams\n",
    "Adapted by AK: Aug 7, 2018\n",
    "See\n",
    "https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/\n",
    "and\n",
    "https://stackoverflow.com/questions/45642077/do-i-need-to-use-one-hot-encoding-if-my-output-variable-is-binary\n",
    "See for explanation about convnet and filters:\n",
    "https://datascience.stackexchange.com/questions/16463/what-is-are-the-default-filters-used-by-keras-convolution2d\n",
    "and\n",
    "http://cs231n.github.io/convolutional-networks/\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import argparse\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.models import model_from_json, Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU, Conv2D, add,\\\n",
    "    Flatten, MaxPooling2D, Dense, Reshape, Input, Dropout, concatenate, Softmax, ReLU\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adadelta, Adam\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelHandler:\n",
    "    \n",
    "    \n",
    "    def createArchitecture(self,model_type,num_classes,input_shape,chain):\n",
    "        '''\n",
    "        Returns a NN model.\n",
    "        modelType: a string which defines the structure of the model\n",
    "        numClasses: a scalar which denotes the number of classes to be predicted\n",
    "        input_shape: a tuple with the dimensions of the input of the model\n",
    "        chain: a string which indicates if must be returned the complete model \n",
    "        up to prediction layer, or a segment of the model.\n",
    "        '''\n",
    "        \n",
    "        if(model_type == 'inception_single'):\n",
    "            input_inc = Input(shape = input_shape)\n",
    "\n",
    "            tower_1 = Conv2D(4, (1,1), padding='same', activation='relu')(input_inc)\n",
    "            tower_1 = Conv2D(8, (2,2), padding='same', activation='relu')(tower_1)\n",
    "            tower_1 = Conv2D(16, (3,3), padding='same', activation='relu')(tower_1)\n",
    "            tower_2 = Conv2D(4, (1,1), padding='same', activation='relu')(input_inc)\n",
    "            tower_2 = Conv2D(16, (3,3), padding='same', activation='relu')(tower_2)\n",
    "            tower_2 = Conv2D(16, (5,5), padding='same', activation='relu')(tower_2)\n",
    "            tower_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_inc)\n",
    "            tower_3 = Conv2D(4, (1,1), padding='same', activation='relu')(tower_3)\n",
    "            \n",
    "            output = concatenate([tower_1, tower_2, tower_3], axis = 3)\n",
    "            \n",
    "            if(chain=='segment'):\n",
    "                architecture = output\n",
    "                \n",
    "            else:\n",
    "                output = Dropout(0.25)(output)\n",
    "                output = Flatten()(output)\n",
    "                out = Dense(num_classes,activation='softmax')(output)\n",
    "                \n",
    "                architecture = Model(inputs = input_inc, outputs = out)\n",
    "\n",
    "        elif(model_type == 'light_image'):\n",
    "            nTx=32\n",
    "            nRx=8\n",
    "            batchsize=64\n",
    "            splits=[0.8,0.2,0.1]\n",
    "            posMatShape=[100,700,1]\n",
    "            nClasses=num_classes\n",
    "            nresblocks=3\n",
    "            nChannels=32\n",
    "            dropout_rate=0.5\n",
    "\n",
    "            conv2D_1 = Conv2D(nChannels, (7, 7), padding=\"same\", activation=\"relu\")\n",
    "            conv2D_2 = Conv2D(nChannels, (3, 3), padding=\"same\", activation=\"relu\")\n",
    "            resBlocks = Sequential()\n",
    "            resBlocks.add(\n",
    "                self.build_resblock(\n",
    "                    input_shape=(*input_shape[:-1], nChannels), nChannels=nChannels)\n",
    "            )\n",
    "            for i in range(nresblocks):\n",
    "                resBlocks.add(\n",
    "                self.build_resblock(\n",
    "                    input_shape=(resBlocks.layers[-1].output_shape[1:]),\n",
    "                    nChannels=nChannels,\n",
    "                ))\n",
    "            dense_1 = Dense(2 * nClasses, activation=\"relu\")\n",
    "            dense_2 = Dense(nClasses, activation=\"relu\")\n",
    "            dropout = Dropout(dropout_rate)\n",
    "            flatten = Flatten()\n",
    "            softmax = Softmax()\n",
    "\n",
    "            input_inc= Input(shape=input_shape)\n",
    "\n",
    "            x = conv2D_1(input_inc)\n",
    "            x = conv2D_2(x)\n",
    "            x = resBlocks(x)\n",
    "            x = flatten(x)\n",
    "            x = dense_1(x)\n",
    "            # if training:\n",
    "            #     x = self.dropout(x, training=training)\n",
    "            x = dropout(x)\n",
    "            x = dense_2(x)\n",
    "            x = softmax(x)\n",
    "            architecture = Model(inputs = input_inc, outputs = x)\n",
    "\n",
    "        \n",
    "        elif(model_type == 'coord_mlp'):\n",
    "            input_coord = Input(shape = input_shape)\n",
    "            \n",
    "            layer = Dense(4,activation='relu')(input_coord)\n",
    "            layer = Dense(16,activation='relu')(layer)\n",
    "            layer = Dense(64,activation='relu')(layer)\n",
    "            out = Dense(num_classes,activation='softmax')(layer)\n",
    "            \n",
    "            architecture = Model(inputs = input_coord, outputs = out)\n",
    "            \n",
    "        elif(model_type == 'lidar_marcus'):\n",
    "            dropProb=0.3\n",
    "            input_lid = Input(shape = input_shape)\n",
    "                        \n",
    "            layer = Conv2D(10,kernel_size=(13,13),\n",
    "                                activation='relu',\n",
    "                                padding=\"SAME\",\n",
    "                                input_shape=input_shape)(input_lid)\n",
    "            layer = Conv2D(30, (11, 11), padding=\"SAME\", activation='relu')(layer)\n",
    "            layer = Conv2D(25, (9, 9), padding=\"SAME\", activation='relu')(layer)\n",
    "            layer = MaxPooling2D(pool_size=(2, 1))(layer)\n",
    "            layer = Dropout(dropProb)(layer)\n",
    "            layer = Conv2D(20, (7, 7), padding=\"SAME\", activation='relu')(layer)\n",
    "            layer = MaxPooling2D(pool_size=(1, 2))(layer)\n",
    "            layer = Conv2D(15, (5, 5), padding=\"SAME\", activation='relu')(layer)\n",
    "            layer = Dropout(dropProb)(layer)\n",
    "            layer = Conv2D(10, (3, 3), padding=\"SAME\", activation='relu')(layer)\n",
    "            layer = Conv2D(1, (1, 1), padding=\"SAME\", activation='relu')(layer)\n",
    "            layer = Flatten()(layer)\n",
    "            out = Dense(num_classes,activation='softmax')(layer)\n",
    "            \n",
    "            architecture = Model(inputs = input_lid, outputs = out)\n",
    "            \n",
    "        elif(model_type == 'lidar_simple'):\n",
    "            dropProb=0.3\n",
    "            input_lid = Input(shape = input_shape)\n",
    "                        \n",
    "            layer = Conv2D(10,kernel_size=(13,13),\n",
    "                                activation='relu',\n",
    "                                padding=\"SAME\",\n",
    "                                input_shape=input_shape)(input_lid)\n",
    "            layer = Conv2D(10, (11, 11), padding=\"SAME\", activation='relu')(layer)\n",
    "            layer = MaxPooling2D(pool_size=(3, 5))(layer)\n",
    "            layer = Dropout(dropProb)(layer)\n",
    "            layer = Conv2D(10, (7, 7), padding=\"SAME\", activation='relu')(layer)\n",
    "            layer = MaxPooling2D(pool_size=(1, 2))(layer)\n",
    "            layer = Dropout(dropProb)(layer)\n",
    "            layer = Conv2D(10, (3, 3), padding=\"SAME\", activation='relu')(layer)\n",
    "            layer = MaxPooling2D(pool_size=(1, 2))(layer)\n",
    "            layer = Dropout(dropProb)(layer)\n",
    "            layer = Flatten()(layer)\n",
    "            out = Dense(num_classes,activation='softmax')(layer)\n",
    "            \n",
    "            architecture = Model(inputs = input_lid, outputs = out)\n",
    "                        \n",
    "        \n",
    "        return architecture\n",
    "\n",
    "    def build_resblock(self, input_shape, nChannels, maxpooling=True):\n",
    "        input = Input(shape=input_shape)\n",
    "        x = Conv2D(nChannels, (3, 3), padding=\"same\", activation=\"relu\")(input)\n",
    "        x = Conv2D(nChannels, (3, 3), padding=\"same\", activation=None)(x)\n",
    "        x = input + x\n",
    "        x = ReLU()(x)\n",
    "        if maxpooling:\n",
    "            x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\")(x)\n",
    "        return Model(inputs=input, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Support functions\n",
    "###############################################################################\n",
    "\n",
    "# For description about top-k, including the explanation on how they treat ties (which can be misleading\n",
    "# if your classifier is outputting a lot of ties (e.g. all 0's will lead to high top-k)\n",
    "# https://www.tensorflow.org/api_docs/python/tf/nn/in_top_k\n",
    "\n",
    "\n",
    "def top_10_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=10)\n",
    "\n",
    "\n",
    "def top_30_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=30)\n",
    "\n",
    "\n",
    "def top_50_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=50)\n",
    "\n",
    "\n",
    "def top_100_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=100)\n",
    "\n",
    "\n",
    "def sub2ind(array_shape, rows, cols):\n",
    "    ind = rows * array_shape[1] + cols\n",
    "    ind[ind < 0] = -1\n",
    "    ind[ind >= array_shape[0] * array_shape[1]] = -1\n",
    "    return ind\n",
    "\n",
    "\n",
    "def ind2sub(array_shape, ind):\n",
    "    ind[ind < 0] = -1\n",
    "    ind[ind >= array_shape[0] * array_shape[1]] = -1\n",
    "    rows = ind.astype(\"int\") / array_shape[1]\n",
    "    cols = ind % array_shape[1]\n",
    "    return (rows, cols)\n",
    "\n",
    "\n",
    "def beamsLogScale(y, thresholdBelowMax):\n",
    "    y_shape = y.shape\n",
    "\n",
    "    for i in range(0, y_shape[0]):\n",
    "        thisOutputs = y[i, :]\n",
    "        logOut = 20 * np.log10(thisOutputs + 1e-30)\n",
    "        minValue = np.amax(logOut) - thresholdBelowMax\n",
    "        zeroedValueIndices = logOut < minValue\n",
    "        thisOutputs[zeroedValueIndices] = 0\n",
    "        thisOutputs = thisOutputs / sum(thisOutputs)\n",
    "        y[i, :] = thisOutputs\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def getBeamOutput(output_file):\n",
    "\n",
    "    thresholdBelowMax = 60\n",
    "\n",
    "    print(\"Reading dataset...\", output_file)\n",
    "    output_cache_file = np.load(output_file)\n",
    "    yMatrix = output_cache_file[\"output_classification\"]\n",
    "\n",
    "    num_classes = 256\n",
    "\n",
    "    pairs = [[i, j] for i in range(8) for j in range(32)]\n",
    "    yMatrix = yMatrix.tolist()\n",
    "    indexes = [pairs.index(yMatrix[item]) for item in range(len(yMatrix))]\n",
    "\n",
    "    y = to_categorical(indexes, num_classes)\n",
    "\n",
    "    # yMatrix = np.abs(yMatrix)\n",
    "\n",
    "    # yMatrix /= np.max(yMatrix)\n",
    "    # yMatrixShape = yMatrix.shape\n",
    "    # num_classes = yMatrix.shape[1] * yMatrix.shape[2]\n",
    "\n",
    "    # y = yMatrix.reshape(yMatrix.shape[0],num_classes)\n",
    "    # y = beamsLogScale(y,thresholdBelowMax)\n",
    "\n",
    "    return y, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Data configuration\n",
    "###############################################################################\n",
    "tf.device(\"/device:GPU:0\")\n",
    "\n",
    "coord = False\n",
    "img = False\n",
    "lidar = True\n",
    "\n",
    "num_epochs = 2\n",
    "batch_size = 32\n",
    "tgtRec = 3\n",
    "seed = 0\n",
    "\n",
    "pathToModel = (\n",
    "    \"./models/\" + str(num_epochs) + \"epochs\"\n",
    ")\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "if coord == True:\n",
    "    # coord_train_input_file = \"/mnt/DATA/codes/mimo-python/simple_street2_part1_60_nTx32_nRx8_coordinates_input.npz\"\n",
    "    coord_train_input_file = (\n",
    "        \"/mnt/DATA/codes/mimo-python/simple_street60_nTx32_nRx8_coordinates_input.npz\"\n",
    "    )\n",
    "    coord_train_cache_file = np.load(coord_train_input_file)\n",
    "    X_coord = coord_train_cache_file[\"input_classification\"]\n",
    "    X_coord_train, X_coord_validation = train_test_split(\n",
    "        X_coord, test_size=0.2, random_state=seed, shuffle=True\n",
    "    )\n",
    "\n",
    "    coord_train_input_shape = X_coord_train.shape\n",
    "\n",
    "if img == True:\n",
    "    nCh = 1  # The number of channels of the image\n",
    "    \n",
    "    # img_train_input_file = \"/mnt/DATA/codes/mimo-python/simple_street2_part1_60_nTx32_nRx8_positionMatrix_input.npz\"\n",
    "    img_train_input_file = \"/mnt/DATA/codes/mimo-python/simple_street60_nTx32_nRx8_positionMatrix_input.npz\"\n",
    "    img_train_cache_file = np.load(img_train_input_file)\n",
    "    X_img = img_train_cache_file[\"input_classification\"]\n",
    "    # X_img_train, X_img_validation = train_test_split(X_img, test_size=0.2, random_state=seed, shuffle=True)\n",
    "    print(\"Reading dataset... \", img_train_input_file)\n",
    "\n",
    "    # img_train_input_shape = X_img_train.shape\n",
    "\n",
    "if lidar == True:\n",
    "    lidar_train_input_file = \"\"\n",
    "    lidar_train_cache_file = np.load(lidar_train_input_file)\n",
    "    X_lidar = lidar_train_cache_file[\"input\"]\n",
    "    X_lidar_train, X_lidar_validation = train_test_split(\n",
    "        X_lidar, test_size=0.2, random_state=seed, shuffle=True\n",
    "    )\n",
    "    print(\"Reading dataset... \", lidar_train_input_file)\n",
    "    lidar_train_input_shape = X_lidar_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Output configuration\n",
    "# output_file = '/mnt/DATA/codes/mimo-python/simple_street2_part1_60_nTx32_nRx8_beams_output.npz'\n",
    "output_file = \"/mnt/DATA/codes/mimo-python/simple_street60_nTx32_nRx8_beams_output.npz\"\n",
    "y_output, num_classes = getBeamOutput(output_file)\n",
    "# y_train, y_validation = train_test_split(y_output, test_size=0.2, random_state=seed, shuffle=True)\n",
    "\n",
    "indices = np.arange(len(y_output))\n",
    "\n",
    "(\n",
    "    X_img_train,\n",
    "    X_img_validation,\n",
    "    y_train,\n",
    "    y_validation,\n",
    "    indices_train,\n",
    "    indices_validation,\n",
    ") = train_test_split(\n",
    "    X_img, y_output, indices, test_size=0.2, random_state=seed, shuffle=True\n",
    ")\n",
    "\n",
    "np.savez(\n",
    "    \"./indices\", indices_train=indices_train, indices_validation=indices_validation\n",
    ")\n",
    "\n",
    "img_train_input_shape = X_img_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Model configuration\n",
    "##############################################################################\n",
    "\n",
    "# multimodal\n",
    "multimodal = [coord, img, lidar]\n",
    "plot = True  # Active Plot output\n",
    "\n",
    "modelHand = ModelHandler()\n",
    "opt = Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=True,\n",
    "    name=\"Adam\",\n",
    ")\n",
    "\n",
    "if coord:\n",
    "    coord_model = modelHand.createArchitecture(\n",
    "        \"coord_mlp\", num_classes, coord_train_input_shape[1], \"complete\"\n",
    "    )\n",
    "if img:\n",
    "    if nCh == 1:\n",
    "        img_model = modelHand.createArchitecture(\n",
    "            \"light_image\",\n",
    "            num_classes,\n",
    "            [img_train_input_shape[1], img_train_input_shape[2], 1],\n",
    "            \"complete\",\n",
    "        )\n",
    "    else:\n",
    "        img_model = modelHand.createArchitecture(\n",
    "            \"light_image\",\n",
    "            num_classes,\n",
    "            [\n",
    "                img_train_input_shape[1],\n",
    "                img_train_input_shape[2],\n",
    "                img_train_input_shape[3],\n",
    "            ],\n",
    "            \"complete\",\n",
    "        )\n",
    "if lidar:\n",
    "    lidar_model = modelHand.createArchitecture(\n",
    "        \"lidar_marcus\",\n",
    "        num_classes,\n",
    "        [\n",
    "            lidar_train_input_shape[1],\n",
    "            lidar_train_input_shape[2],\n",
    "            lidar_train_input_shape[3],\n",
    "        ],\n",
    "        \"complete\",\n",
    "    )\n",
    "\n",
    "if sum(multimodal) == 2:\n",
    "    if coord and lidar:\n",
    "        combined_model = concatenate([coord_model.output, lidar_model.output])\n",
    "        z = Dense(num_classes, activation=\"relu\")(combined_model)\n",
    "        model = Model(inputs=[coord_model.input, lidar_model.input], outputs=z)\n",
    "        model.compile(\n",
    "            loss=categorical_crossentropy,\n",
    "            optimizer=opt,\n",
    "            metrics=[\n",
    "                metrics.categorical_accuracy,\n",
    "                metrics.top_k_categorical_accuracy,\n",
    "                top_10_accuracy,\n",
    "                top_30_accuracy,\n",
    "                top_50_accuracy,\n",
    "                top_100_accuracy,\n",
    "            ],\n",
    "        )\n",
    "        model.summary()\n",
    "        hist = model.fit(\n",
    "            [X_coord_train, X_lidar_train],\n",
    "            y_train,\n",
    "            validation_data=([X_coord_validation, X_lidar_validation], y_validation),\n",
    "            epochs=num_epochs,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "    elif coord and img:\n",
    "        combined_model = concatenate([coord_model.output, img_model.output])\n",
    "        z = Dense(num_classes, activation=\"relu\")(combined_model)\n",
    "        model = Model(inputs=[coord_model.input, img_model.input], outputs=z)\n",
    "        model.compile(\n",
    "            loss=categorical_crossentropy,\n",
    "            optimizer=opt,\n",
    "            metrics=[\n",
    "                metrics.categorical_accuracy,\n",
    "                metrics.top_k_categorical_accuracy,\n",
    "                top_10_accuracy,\n",
    "                top_30_accuracy,\n",
    "                top_50_accuracy,\n",
    "                top_100_accuracy,\n",
    "            ],\n",
    "        )\n",
    "        model.summary()\n",
    "        hist = model.fit(\n",
    "            [X_coord_train, X_img_train],\n",
    "            y_train,\n",
    "            validation_data=([X_coord_validation, X_img_validation], y_validation),\n",
    "            epochs=num_epochs,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        model.save(pathToModel)\n",
    "\n",
    "    else:\n",
    "        combined_model = concatenate([lidar_model.output, img_model.output])\n",
    "        z = Dense(num_classes, activation=\"relu\")(combined_model)\n",
    "        model = Model(inputs=[lidar_model.input, img_model.input], outputs=z)\n",
    "        model.compile(\n",
    "            loss=categorical_crossentropy,\n",
    "            optimizer=opt,\n",
    "            metrics=[\n",
    "                metrics.categorical_accuracy,\n",
    "                metrics.top_k_categorical_accuracy,\n",
    "                top_10_accuracy,\n",
    "                top_30_accuracy,\n",
    "                top_50_accuracy,\n",
    "                top_100_accuracy,\n",
    "            ],\n",
    "        )\n",
    "        model.summary()\n",
    "        hist = model.fit(\n",
    "            [X_lidar_train, X_img_train],\n",
    "            y_train,\n",
    "            validation_data=([X_lidar_validation, X_img_validation], y_validation),\n",
    "            epochs=num_epochs,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "elif sum(multimodal) == 3:\n",
    "    combined_model = concatenate(\n",
    "        [lidar_model.output, img_model.output, coord_model.output]\n",
    "    )\n",
    "    z = Dense(num_classes, activation=\"relu\")(combined_model)\n",
    "    model = Model(\n",
    "        inputs=[lidar_model.input, img_model.input, coord_model.input], outputs=z\n",
    "    )\n",
    "    model.compile(\n",
    "        loss=categorical_crossentropy,\n",
    "        optimizer=opt,\n",
    "        metrics=[\n",
    "            metrics.categorical_accuracy,\n",
    "            metrics.top_k_categorical_accuracy,\n",
    "            top_10_accuracy,\n",
    "            top_30_accuracy,\n",
    "            top_50_accuracy,\n",
    "            top_100_accuracy,\n",
    "        ],\n",
    "    )\n",
    "    model.summary()\n",
    "    hist = model.fit(\n",
    "        [X_lidar_train, X_img_train, X_coord_train],\n",
    "        y_train,\n",
    "        validation_data=(\n",
    "            [X_lidar_validation, X_img_validation, X_coord_validation],\n",
    "            y_validation,\n",
    "        ),\n",
    "        epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    if coord:\n",
    "        model = coord_model\n",
    "        model.compile(\n",
    "            loss=categorical_crossentropy,\n",
    "            optimizer=opt,\n",
    "            metrics=[\n",
    "                metrics.categorical_accuracy,\n",
    "                metrics.top_k_categorical_accuracy,\n",
    "                top_10_accuracy,\n",
    "                top_30_accuracy,\n",
    "                top_50_accuracy,\n",
    "                top_100_accuracy,\n",
    "            ],\n",
    "        )\n",
    "        model.summary()\n",
    "        hist = model.fit(\n",
    "            X_coord_train,\n",
    "            y_train,\n",
    "            validation_data=(X_coord_validation, y_validation),\n",
    "            epochs=num_epochs,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "    elif img:\n",
    "        model = img_model\n",
    "        model.compile(\n",
    "            loss=categorical_crossentropy,\n",
    "            optimizer=opt,\n",
    "            metrics=[\n",
    "                metrics.categorical_accuracy,\n",
    "                metrics.top_k_categorical_accuracy,\n",
    "                top_10_accuracy,\n",
    "                top_30_accuracy,\n",
    "                top_50_accuracy,\n",
    "                top_100_accuracy,\n",
    "            ],\n",
    "        )\n",
    "        model.summary()\n",
    "        hist = model.fit(\n",
    "            X_img_train,\n",
    "            y_train,\n",
    "            validation_data=(X_img_validation, y_validation),\n",
    "            epochs=num_epochs,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        model.save(pathToModel)\n",
    "\n",
    "    else:\n",
    "        model = lidar_model\n",
    "        model.compile(\n",
    "            loss=categorical_crossentropy,\n",
    "            optimizer=opt,\n",
    "            metrics=[\n",
    "                metrics.categorical_accuracy,\n",
    "                metrics.top_k_categorical_accuracy,\n",
    "                top_10_accuracy,\n",
    "                top_30_accuracy,\n",
    "                top_50_accuracy,\n",
    "                top_100_accuracy,\n",
    "            ],\n",
    "        )\n",
    "        model.summary()\n",
    "        hist = model.fit(\n",
    "            X_lidar_train,\n",
    "            y_train,\n",
    "            epochs=num_epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_lidar_validation, y_validation),\n",
    "        )\n",
    "\n",
    "with open(\"history.txt\", \"w\") as f:\n",
    "    f.write(str(hist.history))\n",
    "\n",
    "\"\"\"##Baselines cores\"\"\"\n",
    "\n",
    "beam_weights = {}\n",
    "for i in range(y_train.shape[1]):\n",
    "    beam_weights[i] = 0\n",
    "\n",
    "for i in range(y_train.shape[0]):\n",
    "    scene_array = y_train[i, :]\n",
    "    beam_weights[np.argmax(scene_array)] += 1\n",
    "\n",
    "ocurrence = np.zeros((1, y_validation.shape[1]))\n",
    "oc_factor = sum(beam_weights.values())\n",
    "for b_index in beam_weights.keys():\n",
    "    ocurrence[0, b_index] = beam_weights[b_index] / oc_factor\n",
    "\n",
    "# ocurrence\n",
    "ocurrence_input = np.repeat(ocurrence, y_validation.shape[0], axis=0)\n",
    "ocurrence_output = softmax(ocurrence_input, axis=1)\n",
    "# rand\n",
    "rand_input = np.random.rand(X_img_validation.shape[0], 256)\n",
    "rand_output = softmax(rand_input, axis=1)\n",
    "\n",
    "\"\"\"#Accuracy / epochs\"\"\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "ax.plot(\n",
    "    hist.history[\"categorical_accuracy\"], \"b\", label=\"Categorical accuracy\", linewidth=2\n",
    ")\n",
    "ax.plot(hist.history[\"top_k_categorical_accuracy\"], \"k--\", label=\"Top 5\", linewidth=2)\n",
    "ax.plot(hist.history[\"top_10_accuracy\"], \"m\", label=\"Top 10\", linewidth=2)\n",
    "ax.plot(hist.history[\"top_30_accuracy\"], \"g--\", label=\"Top 30\", linewidth=2)\n",
    "ax.plot(hist.history[\"top_50_accuracy\"], \"r\", label=\"Top 50\", linewidth=2)\n",
    "ax.set(xlabel=\"Epochs\", ylabel=\"Accuracy\")\n",
    "ax.grid()\n",
    "plt.legend()\n",
    "# plt.title('LIDAR data')\n",
    "plt.savefig(\"a.png\")\n",
    "\n",
    "\"\"\"##Creating Baselines\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "predict_top_k = {}\n",
    "ocurrence_top_k = {}\n",
    "random_top_k = {}\n",
    "y_predict = model.predict(X_img_validation)\n",
    "for i in range(1, 51):\n",
    "    predict_top_k[f\"top_{i}\"] = (\n",
    "        np.sum(top_k_categorical_accuracy(y_validation, y_predict, k=i))\n",
    "        / y_predict.shape[0]\n",
    "    )\n",
    "    ocurrence_top_k[f\"top_{i}\"] = (\n",
    "        np.sum(top_k_categorical_accuracy(y_validation, ocurrence_output, k=i))\n",
    "        / y_predict.shape[0]\n",
    "    )\n",
    "    random_top_k[f\"top_{i}\"] = (\n",
    "        np.sum(top_k_categorical_accuracy(y_validation, rand_output, k=i))\n",
    "        / y_predict.shape[0]\n",
    "    )\n",
    "\n",
    "\"\"\"## TOP 10 acurracy\"\"\"\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.hist(predict_top_k[\"top_10\"])\n",
    "plt.hist(ocurrence_top_k[\"top_10\"])\n",
    "plt.hist(random_top_k[\"top_10\"])\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.xlabel(\"Top k\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(list(predict_top_k.values()), label=\"NN\")\n",
    "plt.plot(list(ocurrence_top_k.values()), label=\"Ocurrence\")\n",
    "plt.plot(list(random_top_k.values()), label=\"Dummy\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "\"\"\"# Save output\"\"\"\n",
    "\n",
    "fileNameIdentifier = (\n",
    "    \"./output/\"\n",
    "    + str(num_epochs)\n",
    "    + \"epochs_output\"\n",
    ")\n",
    "f = open(fileNameIdentifier + \".txt\", \"w\")\n",
    "f.write(str(hist.history))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('3.8.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5aaf80bf5bb851baa857fc3e2a05055a4723060c18483edce1107b583200cb68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
